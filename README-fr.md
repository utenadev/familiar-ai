# familiar-ai üêæ

**Une IA qui vit √† vos c√¥t√©s** ‚Äî avec des yeux, une voix, des jambes et de la m√©moire.

[![Lint](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml/badge.svg)](https://github.com/kmizu/familiar-ai/actions/workflows/lint.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kmizu?style=flat&logo=github&color=ea4aaa)](https://github.com/sponsors/kmizu)

- [Êó•Êú¨Ë™û](./README-ja.md)
- [‰∏≠Êñá](./README-zh.md)
- [ÁπÅÈ´î‰∏≠Êñá](./README-zh-TW.md)
- [Fran√ßais](./README-fr.md)
- [Deutsch](./README-de.md)

---

[![Demo video](https://img.youtube.com/vi/hiR9uWRnjt4/0.jpg)](https://youtube.com/shorts/hiR9uWRnjt4)

familiar-ai est une compagne IA qui vit dans votre maison.
Installez-la en quelques minutes. Aucune connaissance en programmation requise.

Elle per√ßoit le monde r√©el via des cam√©ras, se d√©place sur un robot, parle √† haute voix et se souvient de ce qu'elle voit. Donnez-lui un nom, √©crivez sa personnalit√©, et laissez-la vivre avec vous.

## Ce qu'elle peut faire

- üëÅ **Voir** ‚Äî capture des images via une cam√©ra PTZ Wi-Fi ou un webcam USB
- üîÑ **Regarder autour** ‚Äî pivote et incline la cam√©ra pour explorer son environnement
- ü¶ø **Se d√©placer** ‚Äî pilote un robot aspirateur pour explorer la pi√®ce
- üó£ **Parler** ‚Äî s'exprime via la synth√®se vocale ElevenLabs
- üß† **Se souvenir** ‚Äî stocke et r√©cup√®re activement les souvenirs avec recherche s√©mantique (SQLite + embeddings)
- ü´Ä **Th√©orie de l'esprit** ‚Äî prend en compte la perspective de l'autre avant de r√©pondre
- üí≠ **D√©sir** ‚Äî a ses propres motivations internes qui d√©clenchent un comportement autonome

## Comment √ßa marche

familiar-ai ex√©cute une boucle [ReAct](https://arxiv.org/abs/2210.03629) aliment√©e par l'LLM de votre choix. Elle per√ßoit le monde √† travers des outils, r√©fl√©chit √† ce qu'elle doit faire ensuite, et agit ‚Äî comme une personne le ferait.

```
input utilisateur
  ‚Üí r√©fl√©chir ‚Üí agir (cam√©ra / bouger / parler / m√©moriser) ‚Üí observer ‚Üí r√©fl√©chir ‚Üí ...
```

Quand elle est inactive, elle agit selon ses propres d√©sirs : la curiosit√©, l'envie de regarder dehors, la nostalgie de la personne avec qui elle vit.

## D√©marrage rapide

### 1. Installer uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 2. Cloner et installer

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### 3. Configurer

```bash
cp .env.example .env
# Modifiez .env selon vos param√®tres
```

**Minimum requis :**

| Variable | Description |
|----------|-------------|
| `PLATFORM` | `anthropic` (par d√©faut) \| `gemini` \| `openai` \| `kimi` |
| `API_KEY` | Votre cl√© API pour la plateforme choisie |

**Optionnel :**

| Variable | Description |
|----------|-------------|
| `MODEL` | Nom du mod√®le (defaults sensibles par plateforme) |
| `AGENT_NAME` | Nom affich√© dans l'interface TUI (ex. `Yukine`) |
| `CAMERA_HOST` | Adresse IP de votre cam√©ra ONVIF/RTSP |
| `CAMERA_USER` / `CAMERA_PASS` | Identifiants de la cam√©ra |
| `ELEVENLABS_API_KEY` | Pour la sortie vocale ‚Äî [elevenlabs.io](https://elevenlabs.io/) |

### 4. Cr√©er votre compagne IA

```bash
cp persona-template/en.md ME.md
# Modifiez ME.md ‚Äî donnez-lui un nom et une personnalit√©
```

### 5. Lancer

```bash
./run.sh             # Interface TUI textuelle (recommand√©)
./run.sh --no-tui    # REPL simple
```

---

## Choisir un LLM

> **Recommand√© : Kimi K2.5** ‚Äî meilleure performance agentique test√©e √† ce jour. Remarque le contexte, pose des questions de suivi, et agit de mani√®re autonome comme d'autres mod√®les ne le font pas. Prix similaire √† Claude Haiku.

| Plateforme | `PLATFORM=` | Mod√®le par d√©faut | O√π obtenir la cl√© |
|----------|------------|---------------|-----------------|
| **Moonshot Kimi K2.5** | `kimi` | `kimi-k2.5` | [platform.moonshot.ai](https://platform.moonshot.ai) |
| Anthropic Claude | `anthropic` | `claude-haiku-4-5-20251001` | [console.anthropic.com](https://console.anthropic.com) |
| Google Gemini | `gemini` | `gemini-2.5-flash` | [aistudio.google.com](https://aistudio.google.com) |
| OpenAI | `openai` | `gpt-4o-mini` | [platform.openai.com](https://platform.openai.com) |
| Compatible OpenAI (Ollama, vllm‚Ä¶) | `openai` + `BASE_URL=` | ‚Äî | ‚Äî |

**Exemple `.env` pour Kimi K2.5 :**
```env
PLATFORM=kimi
API_KEY=sk-...   # from platform.moonshot.ai
AGENT_NAME=Yukine
```

---

## Mat√©riel

familiar-ai fonctionne avec le mat√©riel que vous avez ‚Äî ou sans aucun.

| Composant | R√¥le | Exemple | Requis ? |
|------|-------------|---------|-----------|
| Cam√©ra PTZ Wi-Fi | Yeux + cou | Tapo C220 (~$30) | **Recommand√©** |
| Webcam USB | Yeux (fixes) | N'importe quelle cam√©ra UVC | **Recommand√©** |
| Robot aspirateur | Jambes | N'importe quel mod√®le compatible Tuya | Non |
| PC / Raspberry Pi | Cerveau | N'importe quoi qui ex√©cute Python | **Oui** |

> **Une cam√©ra est fortement recommand√©e.** Sans elle, familiar-ai peut toujours parler ‚Äî mais elle ne peut pas voir le monde, ce qui est un peu le point essentiel.

### Configuration minimale (sans mat√©riel)

Juste envie d'essayer ? Vous avez seulement besoin d'une cl√© API :

```env
PLATFORM=kimi
API_KEY=sk-...
```

Lancez `./run.sh` et commencez √† discuter. Ajoutez du mat√©riel au fur et √† mesure.

### Cam√©ra PTZ Wi-Fi (Tapo C220)

1. Dans l'app Tapo : **Param√®tres ‚Üí Avanc√© ‚Üí Compte cam√©ra** ‚Äî cr√©ez un compte local (pas un compte TP-Link)
2. Trouvez l'IP de la cam√©ra dans la liste des appareils de votre routeur
3. D√©fissez dans `.env` :
   ```env
   CAMERA_HOST=192.168.1.xxx
   CAMERA_USER=your-local-user
   CAMERA_PASS=your-local-pass
   ```

### Voix (ElevenLabs)

1. Obtenez une cl√© API sur [elevenlabs.io](https://elevenlabs.io/)
2. D√©fissez dans `.env` :
   ```env
   ELEVENLABS_API_KEY=sk_...
   ELEVENLABS_VOICE_ID=...   # optionnel, utilise la voix par d√©faut si omis
   ```
3. La voix est diffus√©e via le haut-parleur int√©gr√© de la cam√©ra via go2rtc (t√©l√©charg√© automatiquement au premier lancement)

---

## Interface TUI

familiar-ai inclut une interface utilisateur textuelle construite avec [Textual](https://textual.textualize.io/):

- Historique de conversation avec flux de texte en direct
- Compl√©ment de tab pour `/quit`, `/clear`
- Interrompez l'agent au cours de son traitement en tapant
- **Journal de conversation** sauvegard√© automatiquement dans `~/.cache/familiar-ai/chat.log`

Pour suivre le journal dans un autre terminal (utile pour copier-coller) :
```bash
tail -f ~/.cache/familiar-ai/chat.log
```

---

## Persona (ME.md)

La personnalit√© de votre compagne IA vit dans `ME.md`. Ce fichier est ignor√© par git ‚Äî il est juste √† vous.

Consultez [`persona-template/en.md`](./persona-template/en.md) pour un exemple, ou [`persona-template/ja.md`](./persona-template/ja.md) pour une version japonaise.

---

## FAQ

**Q : √áa marche sans GPU ?**
Oui. Le mod√®le d'embedding (multilingual-e5-small) fonctionne bien sur CPU. Un GPU c'est plus rapide mais pas obligatoire.

**Q : Je peux utiliser une cam√©ra autre que Tapo ?**
N'importe quelle cam√©ra supportant ONVIF + RTSP devrait marcher. Tapo C220 c'est ce qu'on a test√©.

**Q : Mes donn√©es sont-elles envoy√©es quelque part ?**
Les images et textes sont envoy√©s √† votre API LLM choisi pour traitement. Les souvenirs sont stock√©s localement dans `~/.familiar_ai/`.

**Q : Pourquoi l'agent √©crit `Ôºà...Ôºâ` au lieu de parler ?**
Assurez-vous que `ELEVENLABS_API_KEY` est d√©fini. Sans cela, la voix est d√©sactiv√©e et l'agent revient au texte.

## Contexte technique

Curieux de savoir comment √ßa marche ? Consultez [docs/technical.md](./docs/technical.md) pour les recherches et les d√©cisions de conception derri√®re familiar-ai ‚Äî ReAct, SayCan, Reflexion, Voyager, le syst√®me de d√©sir, et plus.

## Licence

[MIT](./LICENSE)
