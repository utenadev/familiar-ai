# familiar-ai ðŸ¾

**An AI that lives alongside you** â€” with eyes, voice, legs, and memory.

[æ—¥æœ¬èªžç‰ˆã¯ã“ã¡ã‚‰ â†’ README-ja.md](./README-ja.md)

---

familiar-ai is an AI companion that lives in your home.
Set it up in minutes. No coding required.

It perceives the real world through cameras, moves around on a robot body, speaks aloud, and remembers what it sees. Give it a name, write its personality, and let it live with you.

## What it can do

- ðŸ‘ **See** â€” captures images from a Wi-Fi PTZ camera or USB webcam
- ðŸ”„ **Look around** â€” pans and tilts the camera to explore its surroundings
- ðŸ¦¿ **Move** â€” drives a robot vacuum to roam the room
- ðŸ—£ **Speak** â€” talks via ElevenLabs TTS
- ðŸ§  **Remember** â€” stores observations with semantic search (SQLite + embeddings)
- ðŸ’­ **Desire** â€” has its own internal drives that trigger autonomous behavior

## How it works

familiar-ai runs a [ReAct](https://arxiv.org/abs/2210.03629) loop powered by Claude (Anthropic). It perceives the world through tools, thinks about what to do next, and acts â€” just like a person would.

```
user input
  â†’ think â†’ act (camera / move / speak) â†’ observe â†’ think â†’ ...
```

When idle, it acts on its own desires: curiosity, wanting to look outside, missing the person it lives with.

## Getting started

### Requirements

- Python 3.10+
- [uv](https://docs.astral.sh/uv/)
- Anthropic API key
- A camera (Wi-Fi PTZ or USB webcam)

### Install

```bash
git clone https://github.com/lifemate-ai/familiar-ai
cd familiar-ai
uv sync
```

### Configure

```bash
cp .env.example .env
# Fill in your API keys and camera settings
```

### Create your familiar

```bash
cp persona-template/en.md ME.md
# Edit ME.md â€” give it a name and personality
```

### Run

```bash
uv run familiar
```

## Persona (ME.md)

Your familiar's personality lives in `ME.md`. This file is gitignored â€” it's yours alone.

See [`persona-template/en.md`](./persona-template/en.md) for an example, or [`persona-template/ja.md`](./persona-template/ja.md) for a Japanese version.

## Hardware

familiar-ai works with whatever hardware you have â€” or none at all.

| Part | What it does | Example | Required? |
|------|-------------|---------|-----------|
| Wi-Fi PTZ camera | Eyes + neck | Tapo C220 (~$30) | **Recommended** |
| USB webcam | Eyes (fixed) | Any UVC camera | **Recommended** |
| Robot vacuum | Legs | Any Tuya-compatible model | No |
| PC / Raspberry Pi | Brain | Anything that runs Python | **Yes** |

> **A camera is strongly recommended.** Without one, familiar-ai can still talk â€” but it can't see the world, which is kind of the whole point.

Start with a PC, an API key, and a cheap webcam. Add more hardware as you go.

## License

[MIT](./LICENSE)
